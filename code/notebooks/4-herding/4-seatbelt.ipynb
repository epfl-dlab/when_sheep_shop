{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classes.helpers import *\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "from sklearn import linear_model\n",
    "import ast\n",
    "import scipy.stats as ss\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data_folder = '../data/'\n",
    "min_nbr_rats = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the DF with the ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder + 'tmp/time_series_{}_ranks.csv'.format(min_nbr_rats), header=[0,1])\n",
    "\n",
    "# Transform strings into arrays\n",
    "for i in df.index:\n",
    "    for key1 in ['ba', 'rb']:\n",
    "        for key2 in ['dates', 'ratings', 'z_scores', 'ranks']:\n",
    "            arr = ast.literal_eval(df.loc[i][key1][key2])\n",
    "            df.set_value(i, (key1, key2), arr)\n",
    "            \n",
    "diffs = {'ba': [], 'rb': []}\n",
    "\n",
    "for key in diffs.keys():\n",
    "    for i in df.index:\n",
    "        row = df.iloc[i]\n",
    "        diffs[key].append(row[key]['z_scores'][0])\n",
    "\n",
    "thresholds = {}\n",
    "\n",
    "for key in ['ba', 'rb']:\n",
    "    thresholds[key] = {}\n",
    "    thresholds[key]['low'] = np.percentile(diffs[key], 15)\n",
    "    thresholds[key]['high'] = np.percentile(diffs[key], 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-L:\n",
      "  BA:\n",
      "    H: -0.032 [-0.193, 0.123]\n",
      "    L: -0.392 [-0.572, -0.231]\n",
      "  RB:\n",
      "    L: -0.066 [-0.220, 0.099]\n",
      "    H: 0.226 [0.045, 0.393]\n",
      "\n",
      "H-M:\n",
      "  BA:\n",
      "    H: 0.270 [0.225, 0.314]\n",
      "    M: 0.057 [0.006, 0.107]\n",
      "  RB:\n",
      "    M: 0.376 [0.334, 0.423]\n",
      "    H: 0.498 [0.460, 0.542]\n",
      "\n",
      "M-L:\n",
      "  BA:\n",
      "    M: -0.506 [-0.563, -0.450]\n",
      "    L: -0.657 [-0.721, -0.596]\n",
      "  RB:\n",
      "    L: -0.414 [-0.467, -0.363]\n",
      "    M: -0.229 [-0.279, -0.176]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "nbr_draws = 1000\n",
    "\n",
    "min_nbr_rats = 5\n",
    "\n",
    "for to_study in ['H-L', 'H-M', 'M-L']:\n",
    "    \n",
    "    size_ = np.infty\n",
    "    \n",
    "    for cl in [to_study, to_study[::-1]]:\n",
    "\n",
    "\n",
    "        subdf = df[((df['ba']['class'] == cl[0]) & (df['rb']['class'] == cl[-1])) & \n",
    "                   (df['ba']['nbr_ratings'] >= min_nbr_rats) & (df['rb']['nbr_ratings'] >= min_nbr_rats)]    \n",
    "        \n",
    "        if size_ > len(subdf):\n",
    "            size_ = len(subdf)\n",
    "            \n",
    "    nbrs = {'ba': {}, 'rb': {}}\n",
    "\n",
    "    for cl in [to_study, to_study[::-1]]:\n",
    "\n",
    "        cls = {'ba': cl[0], 'rb': cl[-1]}\n",
    "\n",
    "        subdf = df[((df['ba']['class'] == cl[0]) & (df['rb']['class'] == cl[-1])) & \n",
    "                   (df['ba']['nbr_ratings'] >= min_nbr_rats) & (df['rb']['nbr_ratings'] >= min_nbr_rats)] \n",
    "        subdf.index = range(len(subdf))\n",
    "        \n",
    "        subdf = subdf.loc[np.random.choice(len(subdf), size_, replace=False)]\n",
    "        \n",
    "        for key in ['ba', 'rb']:\n",
    "\n",
    "            nbrs[key][cls[key]] = {}\n",
    "\n",
    "            ranks = np.array([r[min_nbr_rats-1] for r in subdf[key]['z_scores']])\n",
    "\n",
    "            nbrs[key][cls[key]]['avg'] = np.mean(ranks)\n",
    "\n",
    "            tmp = []\n",
    "            # Go through each draw\n",
    "            for d in range(nbr_draws):\n",
    "\n",
    "                # Get the indices\n",
    "                idx = np.random.randint(0, len(subdf[key]), len(subdf[key]))\n",
    "\n",
    "                ranks_tmp = ranks[idx]\n",
    "\n",
    "                tmp.append(np.mean(ranks_tmp))\n",
    "            nbrs[key][cls[key]]['low'] = np.percentile(tmp, 2.5)\n",
    "            nbrs[key][cls[key]]['high'] = np.percentile(tmp, 97.5)\n",
    "        \n",
    "\n",
    "    print('{}:'.format(to_study))\n",
    "    for key in nbrs:\n",
    "        print('  {}:'.format(key.upper()))\n",
    "        for key2 in nbrs[key]:\n",
    "            print('    {}: {:.3f} [{:.3f}, {:.3f}]'.format(key2, nbrs[key][key2]['avg'], nbrs[key][key2]['low'], nbrs[key][key2]['high']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
